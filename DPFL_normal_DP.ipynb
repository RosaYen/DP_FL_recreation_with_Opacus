{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Differentially Private Deep Learning in 20 lines of code**\n",
    "\n",
    "This is a step-by-step tutorial on how to train a simple PyTorch classification model on MNIST dataset using a differentially private - stochastic gradient descent optimizer in 20 lines of code using the PyTorch opacus library.  \n",
    "\n",
    "Link to blogpost: https://blog.openmined.org/differentially-private-deep-learning-using-opacus-in-20-lines-of-code/\n",
    "\n",
    "Link to library: https://github.com/pytorch/opacus\n",
    "\n",
    "Author: Kritika Prakash, OpenMined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Importing PyTorch and Opacus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from opacus import PrivacyEngine\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: Loading MNIST data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../mnist',\n",
    "                   train=True,\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.1307,), (0.3081,)),]),),\n",
    "                   batch_size=64,\n",
    "                   shuffle=True,\n",
    "                   num_workers=1,\n",
    "                   pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../mnist', \n",
    "                       train=False, \n",
    "                       transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                                     transforms.Normalize((0.1307,), (0.3081,)),]),), \n",
    "                       batch_size=1024,\n",
    "                       shuffle=True,\n",
    "                       num_workers=1,\n",
    "                       pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: Creating a Neural Network Classification Model and Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 16, 8, 2, padding=3),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(2, 1),\n",
    "        torch.nn.Conv2d(16, 32, 4, 2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(2, 1),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(32 * 4 * 4, 32),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(32, 10))\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4: Creating and Attaching a Differential Privacy Engine to the Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rosa/opacus-master/opacus/privacy_engine.py:104: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
     ]
    }
   ],
   "source": [
    "privacy_engine = PrivacyEngine(\n",
    "    model,\n",
    "    batch_size=64,\n",
    "    sample_size=60000,\n",
    "    alphas=range(2,32),\n",
    "    noise_multiplier=1.3,\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "privacy_engine.attach(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5: Creating a training function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch, device, delta):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    \n",
    "    epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(delta)\n",
    "    print(\n",
    "        f\"Train Epoch: {epoch} \\t\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"(ε = {epsilon:.2f}, δ = {delta}) for α = {best_alpha}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6: Training the private model over multiple epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 937/938 [00:17<00:00, 61.35it/s]/home/rosa/opacus-master/opacus/privacy_engine.py:280: UserWarning: PrivacyEngine expected a batch of size 64 but the last step received a batch of size 32. This means that the privacy analysis will be a bit more pessimistic. You can set `drop_last = True` in your PyTorch dataloader to avoid this problem completely\n",
      "  f\"PrivacyEngine expected a batch of size {self.batch_size} \"\n",
      "100%|██████████| 938/938 [00:17<00:00, 54.60it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLoss: 1.335555 (ε = 0.55, δ = 1e-05) for α = 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 61.63it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 \tLoss: 0.609898 (ε = 0.57, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 61.15it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 \tLoss: 0.552978 (ε = 0.58, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.95it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 \tLoss: 0.510128 (ε = 0.59, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 61.18it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 \tLoss: 0.482147 (ε = 0.60, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.88it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 \tLoss: 0.466153 (ε = 0.61, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.79it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 \tLoss: 0.478283 (ε = 0.62, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.36it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 \tLoss: 0.469972 (ε = 0.63, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 61.71it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 \tLoss: 0.463410 (ε = 0.64, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 61.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 \tLoss: 0.486159 (ε = 0.65, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(model, train_loader, optimizer, epoch, device=\"cpu\", delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epoch = [*range(1,11,1)]\n",
    "epsilon = [0.55, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65]\n",
    "loss = [1.162757, 0.595237, 0.579614, 0.522272, 0.507108, 0.526577, 0.530179, 0.528997, 0.525267, 0.540919]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4b22164f60>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch, epsilon, label=\"epsilon\")\n",
    "plt.plot(epoch, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Putting the code all together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rosa/opacus-master/opacus/privacy_engine.py:104: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "100%|█████████▉| 937/938 [00:10<00:00, 89.74it/s]/home/rosa/opacus-master/opacus/privacy_engine.py:280: UserWarning: PrivacyEngine expected a batch of size 64 but the last step received a batch of size 32. This means that the privacy analysis will be a bit more pessimistic. You can set `drop_last = True` in your PyTorch dataloader to avoid this problem completely\n",
      "  f\"PrivacyEngine expected a batch of size {self.batch_size} \"\n",
      "100%|██████████| 938/938 [00:10<00:00, 87.92it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLoss: 1.183973 (ε = 0.55, δ = 1e-05) for α = 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 87.06it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 \tLoss: 0.514143 (ε = 0.57, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 87.35it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 \tLoss: 0.468444 (ε = 0.58, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 86.37it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 \tLoss: 0.483729 (ε = 0.59, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 86.20it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 \tLoss: 0.459814 (ε = 0.60, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 86.53it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 \tLoss: 0.462071 (ε = 0.61, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 88.20it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 \tLoss: 0.491132 (ε = 0.62, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 86.71it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 \tLoss: 0.495203 (ε = 0.63, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 88.04it/s]\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 \tLoss: 0.526300 (ε = 0.64, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 87.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 \tLoss: 0.531549 (ε = 0.65, δ = 1e-05) for α = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Importing PyTorch and Opacus\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from opacus import PrivacyEngine\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 2: Loading MNIST Data\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('../mnist', train=True, download=True,\n",
    "               transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), \n",
    "               (0.3081,)),]),), batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('../mnist', train=False, \n",
    "              transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), \n",
    "              (0.3081,)),]),), batch_size=1024, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "# Step 3: Creating a PyTorch Neural Network Classification Model and Optimizer\n",
    "model = torch.nn.Sequential(torch.nn.Conv2d(1, 16, 8, 2, padding=3), torch.nn.ReLU(), torch.nn.MaxPool2d(2, 1),\n",
    "        torch.nn.Conv2d(16, 32, 4, 2),  torch.nn.ReLU(), torch.nn.MaxPool2d(2, 1), torch.nn.Flatten(), \n",
    "        torch.nn.Linear(32 * 4 * 4, 32), torch.nn.ReLU(), torch.nn.Linear(32, 10))\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    "\n",
    "# Step 4: Attaching a Differential Privacy Engine to the Optimizer\n",
    "privacy_engine = PrivacyEngine(model, batch_size=64, sample_size=60000, alphas=range(2,32), \n",
    "                               noise_multiplier=1.3, max_grad_norm=1.0,)\n",
    "\n",
    "privacy_engine.attach(optimizer)\n",
    "\n",
    "# Step 5: Training the private model over multiple epochs\n",
    "def train(model, train_loader, optimizer, epoch, device, delta):\n",
    "    \n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    \n",
    "    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(delta)\n",
    "    \n",
    "    print(\n",
    "        f\"Train Epoch: {epoch} \\t\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"(ε = {epsilon:.2f}, δ = {delta}) for α = {best_alpha}\"\n",
    "    )\n",
    "    \n",
    "for epoch in range(1, 11):\n",
    "    train(model, train_loader, optimizer, epoch, device=\"cpu\", delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
